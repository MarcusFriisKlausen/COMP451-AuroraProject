{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Model Training\n",
    "Requires python 3.9-3.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class AuroraDataset(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (numpy.ndarray): Feature matrix\n",
    "            Y (numpy.ndarray): Target vector\n",
    "            transform (callable, optional): Optional transform to be applied on features\n",
    "        \"\"\"\n",
    "        # Convert numpy arrays to torch tensors\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generate one sample of data\n",
    "        \"\"\"\n",
    "        features = self.X[idx]\n",
    "        target = self.Y[idx]\n",
    "        \n",
    "        # Optional transform\n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "        \n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aurora_dataloader(X, Y, batch_size=32, shuffle=True, transform=None):\n",
    "    \"\"\"\n",
    "    Create a DataLoader for Aurora dataset\n",
    "    \n",
    "    Args:\n",
    "        X (numpy.ndarray): Feature matrix\n",
    "        Y (numpy.ndarray): Target vector\n",
    "        batch_size (int): Number of samples per batch\n",
    "        shuffle (bool): Whether to shuffle the data\n",
    "        transform (callable, optional): Optional transform to be applied on features\n",
    "    \n",
    "    Returns:\n",
    "        torch.utils.data.DataLoader: DataLoader for the Aurora dataset\n",
    "    \"\"\"\n",
    "    dataset = AuroraDataset(X, Y, transform)\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=shuffle,\n",
    "        num_workers=0  # Set to 0 or adjust based on your system\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuroraNN(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        \"\"\"\n",
    "        Simple neural network for aurora visibility classification\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): Number of input features\n",
    "        \"\"\"\n",
    "        super(AuroraNN, self).__init__()\n",
    "        \n",
    "        # Define network layers\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(32, 1),\n",
    "            torch.nn.Sigmoid()  # Binary classification\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_aurora_model(X_train, Y_train, X_test, Y_test, epochs=50, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Train the aurora visibility classification model\n",
    "    \n",
    "    Args:\n",
    "        X_train (numpy.ndarray): Training feature matrix\n",
    "        Y_train (numpy.ndarray): Training target vector\n",
    "        X_test (numpy.ndarray): Test feature matrix\n",
    "        Y_test (numpy.ndarray): Test target vector\n",
    "        epochs (int): Number of training epochs\n",
    "        learning_rate (float): Learning rate for optimizer\n",
    "    \n",
    "    Returns:\n",
    "        torch.nn.Module: Trained model\n",
    "    \"\"\"\n",
    "    # Create dataloaders\n",
    "    train_loader = create_aurora_dataloader(X_train, Y_train, batch_size=32, shuffle=True)\n",
    "    test_loader = create_aurora_dataloader(X_test, Y_test, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = AuroraNN(input_size=X_train.shape[1])\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = torch.nn.BCELoss()  # Binary Cross Entropy for binary classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_features, batch_targets in train_loader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs.squeeze(), batch_targets)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Validation/Test evaluation\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_targets in test_loader:\n",
    "                outputs = model(batch_features)\n",
    "                test_batch_loss = criterion(outputs.squeeze(), batch_targets)\n",
    "                test_loss += test_batch_loss.item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                predicted = (outputs.squeeze() > 0.5).float()\n",
    "                correct += (predicted == batch_targets).sum().item()\n",
    "                total += batch_targets.size(0)\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        print(f'Epoch [{epoch+1}/{epochs}]')\n",
    "        print(f'Training Loss: {total_loss/len(train_loader):.4f}')\n",
    "        print(f'Test Loss: {test_loss/len(test_loader):.4f}')\n",
    "        print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "dataset = np.load(\"data_processed/aurorae_dataset.npy\", allow_pickle=True)\n",
    "\n",
    "# every column but the last ('aurora_visible')\n",
    "X = dataset[:, :-1]\n",
    "# last column ('aurora_visible')\n",
    "Y = dataset[:, -1]\n",
    "\n",
    "X_train = X[:500]\n",
    "Y_train = Y[:500]\n",
    "X_test = X[-167:]\n",
    "Y_test = Y[-167:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_aurora_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[73], line 17\u001b[0m, in \u001b[0;36mtrain_aurora_model\u001b[1;34m(X_train, Y_train, X_test, Y_test, epochs, learning_rate)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mTrain the aurora visibility classification model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    torch.nn.Module: Trained model\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create dataloaders\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_aurora_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m create_aurora_dataloader(X_test, Y_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Initialize model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[71], line 15\u001b[0m, in \u001b[0;36mcreate_aurora_dataloader\u001b[1;34m(X, Y, batch_size, shuffle, transform)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_aurora_dataloader\u001b[39m(X, Y, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Create a DataLoader for Aurora dataset\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m        torch.utils.data.DataLoader: DataLoader for the Aurora dataset\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mAuroraDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     18\u001b[0m         dataset, \n\u001b[0;32m     19\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[0;32m     20\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m     21\u001b[0m         num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Set to 0 or adjust based on your system\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataloader\n",
      "Cell \u001b[1;32mIn[70], line 20\u001b[0m, in \u001b[0;36mAuroraDataset.__init__\u001b[1;34m(self, X, Y, transform)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    X (numpy.ndarray): Feature matrix\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    Y (numpy.ndarray): Target vector\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    transform (callable, optional): Optional transform to be applied on features\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Convert numpy arrays to torch tensors\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(Y, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "train_aurora_model(X_train, Y_train, X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
